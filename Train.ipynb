{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083de893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432aed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a0c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  when modi promised “minimum government maximum...   -1.0\n",
       "1  talk all the nonsense and continue all the dra...    0.0\n",
       "2  what did just say vote for modi  welcome bjp t...    1.0\n",
       "3  asking his supporters prefix chowkidar their n...    1.0\n",
       "4  answer who among these the most powerful world...    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdf0e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    72250\n",
       " 0.0    55213\n",
       "-1.0    35510\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a413ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df['label'].apply(lambda x: 0 if x==0 else (1 if x==1 else 2))\n",
    "df['review'] = df['review'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375552ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  when modi promised “minimum government maximum...      2\n",
       "1  talk all the nonsense and continue all the dra...      0\n",
       "2  what did just say vote for modi  welcome bjp t...      1\n",
       "3  asking his supporters prefix chowkidar their n...      1\n",
       "4  answer who among these the most powerful world...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0b5a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    72250\n",
       "0    55213\n",
       "2    35517\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac2037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "\n",
    "sw=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef69554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df,choice):\n",
    "    df = df.applymap(lambda s: s.lower() if type(s) == str else s) \n",
    "    df[\"review\"]=df[\"review\"].str.replace(\"[^\\w\\s]\",\"\") \n",
    "    df[\"review\"]=df[\"review\"].str.replace(\"\\d\",\"\") \n",
    "    df[\"review\"]=df[\"review\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw)) \n",
    "    if choice == 1:\n",
    "        df[\"review\"]=df[\"review\"].apply(lambda x: \" \".join(Word(i).lemmatize() for i in x.split()))\n",
    "    elif choice == 2:\n",
    "        df[\"review\"]=df[\"review\"].apply(lambda x: \" \".join(Word(i).stem() for i in x.split())) \n",
    "    return df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e58bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OUZHAN~1\\AppData\\Local\\Temp/ipykernel_10332/2258081419.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"review\"]=df[\"review\"].str.replace(\"[^\\w\\s]\",\"\")\n",
      "C:\\Users\\OUZHAN~1\\AppData\\Local\\Temp/ipykernel_10332/2258081419.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"review\"]=df[\"review\"].str.replace(\"\\d\",\"\")\n"
     ]
    }
   ],
   "source": [
    "df['review']=data_cleaning(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d3162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8616b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df,max_features):\n",
    "    print(\"TF-IDF yöntemi seçildi\")\n",
    "    vectorizer = TfidfVectorizer(lowercase=False,ngram_range=(1,2),dtype=np.byte,max_features=max_features)\n",
    "    X = vectorizer.fit_transform(df['review'].tolist())\n",
    "    return X,vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da9c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF yöntemi seçildi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2029: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int8'> 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X,vectorizer=feature_extraction(df,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb36665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953eaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,df['label'],random_state=1,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f96db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996bf74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on traning data:  0.939436331656236\n",
      "Accuracy Score on test data:  0.8519327524849675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87     13910\n",
      "           1       0.88      0.88      0.88     17972\n",
      "           2       0.87      0.66      0.75      8863\n",
      "\n",
      "    accuracy                           0.85     40745\n",
      "   macro avg       0.85      0.83      0.83     40745\n",
      "weighted avg       0.86      0.85      0.85     40745\n",
      "\n",
      "Accuracy Score:  0.8519327524849675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "model_lr=lr.fit(X_train,y_train)\n",
    "prediction_lr=model_lr.predict(X_test)\n",
    "print(\"Accuracy Score on traning data: \",lr.score(X_train,y_train))\n",
    "print(\"Accuracy Score on test data: \",lr.score(X_test,y_test))\n",
    "print(classification_report(y_test, prediction_lr))\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, prediction_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66233219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on traning data:  0.9938397349368021\n",
      "Accuracy Score on test data:  0.8520554669284575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87     13910\n",
      "           1       0.89      0.86      0.88     17972\n",
      "           2       0.86      0.70      0.77      8863\n",
      "\n",
      "    accuracy                           0.85     40745\n",
      "   macro avg       0.85      0.83      0.84     40745\n",
      "weighted avg       0.86      0.85      0.85     40745\n",
      "\n",
      "Accuracy Score:  0.8520554669284575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "rc=RidgeClassifier()\n",
    "model_rc=rc.fit(X_train,y_train)\n",
    "prediction_rc=model_rc.predict(X_test)\n",
    "print(\"Accuracy Score on traning data: \",rc.score(X_train,y_train))\n",
    "print(\"Accuracy Score on test data: \",rc.score(X_test,y_test))\n",
    "print(classification_report(y_test, prediction_rc))\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, prediction_rc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6193fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on traning data:  0.9988792080827913\n",
      "Accuracy Score on test data:  0.8636887961713093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88     13910\n",
      "           1       0.91      0.87      0.89     17972\n",
      "           2       0.84      0.74      0.79      8863\n",
      "\n",
      "    accuracy                           0.86     40745\n",
      "   macro avg       0.86      0.85      0.85     40745\n",
      "weighted avg       0.87      0.86      0.86     40745\n",
      "\n",
      "Accuracy Score:  0.8636887961713093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "pt=Perceptron()\n",
    "model_pt=pt.fit(X_train,y_train)\n",
    "prediction_pt=model_pt.predict(X_test)\n",
    "print(\"Accuracy Score on traning data: \",pt.score(X_train,y_train))\n",
    "print(\"Accuracy Score on test data: \",pt.score(X_test,y_test))\n",
    "print(classification_report(y_test, prediction_pt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, prediction_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89cee945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on traning data:  0.8427046263345196\n",
      "Accuracy Score on test data:  0.8229721438213278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     13910\n",
      "           1       0.89      0.82      0.85     17972\n",
      "           2       0.86      0.62      0.72      8863\n",
      "\n",
      "    accuracy                           0.82     40745\n",
      "   macro avg       0.83      0.80      0.80     40745\n",
      "weighted avg       0.83      0.82      0.82     40745\n",
      "\n",
      "Accuracy Score:  0.8229721438213278\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "model_xgb=xgb.fit(X_train,y_train)\n",
    "prediction_xgb=model_xgb.predict(X_test)\n",
    "print(\"Accuracy Score on traning data: \",xgb.score(X_train,y_train))\n",
    "print(\"Accuracy Score on test data: \",xgb.score(X_test,y_test))\n",
    "print(classification_report(y_test, prediction_xgb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, prediction_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd1e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on traning data:  0.8701272139730847\n",
      "Accuracy Score on test data:  0.8619217081850534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     13910\n",
      "           1       0.92      0.86      0.89     17972\n",
      "           2       0.87      0.71      0.78      8863\n",
      "\n",
      "    accuracy                           0.86     40745\n",
      "   macro avg       0.86      0.84      0.85     40745\n",
      "weighted avg       0.87      0.86      0.86     40745\n",
      "\n",
      "Accuracy Score:  0.8619217081850534\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "model_lgbm=lgbm.fit(X_train,y_train)\n",
    "prediction_lgbm=model_lgbm.predict(X_test)\n",
    "print(\"Accuracy Score on traning data: \",lgbm.score(X_train,y_train))\n",
    "print(\"Accuracy Score on test data: \",lgbm.score(X_test,y_test))\n",
    "print(classification_report(y_test, prediction_lgbm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, prediction_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca2c5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9506507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_lr, open('logistic.sav', 'wb'))\n",
    "pickle.dump(model_rc, open('ridge.sav', 'wb'))\n",
    "pickle.dump(model_pt, open('perceptron.sav', 'wb'))\n",
    "pickle.dump(model_xgb, open('xgb.sav', 'wb'))\n",
    "pickle.dump(model_lgbm, open('lgbm.sav', 'wb'))\n",
    "pickle.dump(vectorizer, open('tfidf_vectorizer.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
